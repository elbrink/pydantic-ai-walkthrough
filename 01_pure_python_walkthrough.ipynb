{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure Python Walkthrough\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function logfire._internal.instrument.instrument.<locals>.decorator(func: 'Callable[P, R]') -> 'Callable[P, R]'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=813962;https://logfire-eu.pydantic.dev/elbrink/claude-test\u001b\\\u001b[4;36mhttps://logfire-eu.pydantic.dev/elbrink/claude-test\u001b[0m\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import logfire\n",
    "\n",
    "import tool_functions as tf\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "model = os.getenv(\"DEFAULT_MODEL\")\n",
    "logfire_token = os.getenv(\"LOGFIRE_TOKEN\")\n",
    "\n",
    "\n",
    "# configure logfire\n",
    "logfire.configure(token=logfire_token)\n",
    "\n",
    "# 2. Instrumenteer LangChain (automatisch loggen van chains, LLM calls, tools, etc.)\n",
    "logfire.instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Definieer een basis agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "model = os.getenv(\"DEFAULT_MODEL\")\n",
    "\n",
    "import json\n",
    "from anthropic import Anthropic\n",
    "from typing import Dict, List, Optional, Callable, Any\n",
    "\n",
    "\n",
    "class LLMAgent:\n",
    "    def __init__(self, name: str, system_prompt: str = \"\"):\n",
    "        \"\"\"\n",
    "        Initialiseer de LLM-agent.\n",
    "\n",
    "        Args:\n",
    "            name: Naam van de agent\n",
    "            system_prompt: Systeeminstructies voor de agent\n",
    "        \"\"\"\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def execute_tool(self, tool_name: str, **kwargs) -> str:\n",
    "        \"\"\"\n",
    "        Voer een tool uit met de gegeven parameters.\n",
    "        \"\"\"\n",
    "        if tool_name in self.tools:\n",
    "            try:\n",
    "                result = self.tools[tool_name][\"function\"](**kwargs)\n",
    "                return f\"Tool '{tool_name}' executed successfully. Result: {result}\"\n",
    "            except Exception as e:\n",
    "                return f\"Error executing tool '{tool_name}': {str(e)}\"\n",
    "        return f\"Tool '{tool_name}' not found.\"\n",
    "\n",
    "    @logfire.instrument()\n",
    "    def run(self, user_input: str) -> str:\n",
    "        \"\"\"\n",
    "        Verwerk gebruikersinvoer en genereer een reactie.\n",
    "        \"\"\"\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            system=self.system_prompt,\n",
    "            messages=[{\"role\": \"user\", \"content\": user_input}],\n",
    "        )\n",
    "\n",
    "        # Extract the response text\n",
    "        response_text = (\n",
    "            response.content[0].text if hasattr(response, \"content\") else response\n",
    "        )\n",
    "        # Log the response to Logfire\n",
    "        logfire.info(\n",
    "            \"Agent response generated\",\n",
    "            agent_name=self.name,\n",
    "            user_input=user_input,\n",
    "            response=response_text,\n",
    "            model=self.model,\n",
    "            response_length=len(response_text),\n",
    "        )\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "basic_agent = LLMAgent(\n",
    "    name=\"basic_agent\",\n",
    "    system_prompt=\"je bent een agent die op alle vragen een verstandig antwoord geeft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stel een vraag aan de agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:22:19.578 Calling __main__.LLMAgent.run\n",
      "12:22:25.789   Agent response generated\n",
      "Hier is een heldere definitie van een agent:\n",
      "\n",
      "Een agent is een systeem of entiteit dat:\n",
      "\n",
      "1. Waarnemingen kan doen in zijn omgeving\n",
      "2. Doelgericht kan redeneren\n",
      "3. Beslissingen kan nemen\n",
      "4. Acties kan uitvoeren om specifieke doelen te bereiken\n",
      "\n",
      "Er zijn verschillende soorten agenten:\n",
      "- Softwareagenten (computerprogramma's)\n",
      "- Fysieke agenten (robots)\n",
      "- Menselijke agenten (bijvoorbeeld politieagenten)\n",
      "- Intelligente agenten (systemen met AI)\n",
      "\n",
      "Belangrijke kenmerken van een agent zijn:\n",
      "- Autonomie\n",
      "- Reactievermogen\n",
      "- Pro-activiteit\n",
      "- Sociale vaardigheid\n",
      "- Adaptief vermogen\n",
      "\n",
      "In de kunstmatige intelligentie wordt een agent gezien als een systeem dat waarnemingen ontvangt via sensoren en vervolgens handelingen verricht via actuatoren, met als doel het behalen van specifieke prestaties.\n"
     ]
    }
   ],
   "source": [
    "# Run the agent\n",
    "result = basic_agent.run(\"geef een defintie van een agent\")\n",
    "\n",
    "\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definieer tools voor de agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic Tool Definitions (voor Pure Python)\n",
    "ANTHROPIC_TOOLS = [\n",
    "    {\n",
    "        \"name\": \"calculate_btw\",\n",
    "        \"description\": \"Bereken BTW (belasting toegevoegde waarde) over een bedrag. Standaard BTW tarief is 21%.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"bedrag\": {\"type\": \"number\", \"description\": \"Het bedrag exclusief BTW\"},\n",
    "                \"btw_percentage\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"BTW percentage (standaard 21%)\",\n",
    "                    \"default\": 21.0,\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"bedrag\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"calculate_discount\",\n",
    "        \"description\": \"Bereken korting over een bedrag.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"bedrag\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Het oorspronkelijke bedrag\",\n",
    "                },\n",
    "                \"korting_percentage\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Korting percentage\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"bedrag\", \"korting_percentage\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_inwoners_gemeente\",\n",
    "        \"description\": \"Haal inwonersaantallen op van Nederlandse gemeenten via CBS API. Kan specifieke gemeente opzoeken of top 10 grootste gemeenten tonen.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"gemeente_naam\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Naam van de gemeente (optioneel). Laat leeg voor top 10 grootste gemeenten.\",\n",
    "                },\n",
    "                \"jaar\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Jaar voor de data (standaard 2023)\",\n",
    "                    \"default\": \"2023\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# Tool function mapping\n",
    "TOOL_FUNCTIONS = {\n",
    "    \"calculate_btw\": tf.calculate_btw,\n",
    "    \"calculate_discount\": tf.calculate_discount,\n",
    "    \"get_inwoners_gemeente\": tf.get_inwoners_gemeente,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolAgent(LLMAgent):\n",
    "    def __init__(self, name: str, system_prompt: str = \"\"):\n",
    "        super().__init__(name, system_prompt)\n",
    "        self.tools = ANTHROPIC_TOOLS\n",
    "\n",
    "    @logfire.instrument()\n",
    "    def run(self, user_input: str) -> str:\n",
    "\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            tools=self.tools,\n",
    "            messages=[{\"role\": \"user\", \"content\": user_input}],\n",
    "        )\n",
    "        # Extract the response text\n",
    "        response_text = (\n",
    "            response.content[0].text if hasattr(response, \"content\") else response\n",
    "        )\n",
    "        # Log the response to Logfire\n",
    "        logfire.info(\n",
    "            \"Agent response generated\",\n",
    "            agent_name=self.name,\n",
    "            user_input=user_input,\n",
    "            response=response_text,\n",
    "            model=self.model,\n",
    "            response_length=len(response_text),\n",
    "        )\n",
    "\n",
    "        # Check if Claude wants to use tools\n",
    "        if response.stop_reason == \"tool_use\":\n",
    "            tool_results = []\n",
    "\n",
    "            for content in response.content:\n",
    "                if content.type == \"tool_use\":\n",
    "                    tool_name = content.name\n",
    "                    tool_input = content.input\n",
    "                    tool_id = content.id\n",
    "\n",
    "                    print(\n",
    "                        f\"ðŸ”§ Claude gebruikt tool: {tool_name} met input: {tool_input}\"\n",
    "                    )\n",
    "\n",
    "                    # Execute the tool\n",
    "                    if tool_name in TOOL_FUNCTIONS:\n",
    "                        result = TOOL_FUNCTIONS[tool_name](**tool_input)\n",
    "                        tool_results.append(\n",
    "                            {\n",
    "                                \"type\": \"tool_result\",\n",
    "                                \"tool_use_id\": tool_id,\n",
    "                                \"content\": json.dumps(result),\n",
    "                            }\n",
    "                        )\n",
    "                    else:\n",
    "                        print(f\"Tool {tool_name} not found\")\n",
    "\n",
    "            # Get final response with tool results\n",
    "            final_response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                max_tokens=5000,\n",
    "                tools=self.tools,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": user_input},\n",
    "                    {\"role\": \"assistant\", \"content\": response.content},\n",
    "                    {\"role\": \"user\", \"content\": tool_results},\n",
    "                ],\n",
    "            )\n",
    "            # Log the final response to Logfire\n",
    "            logfire.info(\n",
    "                \"Agent response generated\",\n",
    "                agent_name=self.name,\n",
    "                user_input=user_input,\n",
    "                response=final_response,\n",
    "            )\n",
    "            return final_response\n",
    "        else:\n",
    "            return response\n",
    "\n",
    "\n",
    "tool_agent = ToolAgent(\n",
    "    name=\"tool_agent\",\n",
    "    system_prompt=\"je bent een agent die op alle vragen een verstandig antwoord geeft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test een aantal tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:30:58.453 Calling __main__.ToolAgent.run\n",
      "12:31:01.331   Agent response generated\n",
      "ðŸ”§ Claude gebruikt tool: calculate_btw met input: {'bedrag': 100}\n",
      "12:31:03.919   Agent response generated\n",
      "Stap 2: Korting Berekening\n",
      "Nu bereken ik de korting van 15% over het totale bedrag inclusief BTW.\n"
     ]
    }
   ],
   "source": [
    "result2 = tool_agent.run(\n",
    "    \"ik koop een product X voor 100 euro exclusief BTW, bereken de BTW. Ik krijg van de leverancier ook nog 15% korting op het bedrag inclusief BTW. Geef een overzicht wat ik moet betalen en hoe dat is samengesteld\"\n",
    ")\n",
    "\n",
    "print(result2.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:31:08.480 Calling __main__.ToolAgent.run\n",
      "12:31:13.136   Agent response generated\n",
      "ðŸ”§ Claude gebruikt tool: get_inwoners_gemeente met input: {'jaar': '2025'}\n",
      "ðŸ”§ Claude gebruikt tool: get_inwoners_gemeente met input: {'gemeente_naam': 'Groningen', 'jaar': '2025'}\n",
      "12:31:20.201   Agent response generated\n",
      "Op basis van de gegevens voor het jaar 2025 kan ik je het volgende overzicht geven:\n",
      "\n",
      "Top 7 gemeenten in Nederland naar aantal inwoners in 2025:\n",
      "1. Amsterdam: 935.793 inwoners\n",
      "2. Rotterdam: 672.330 inwoners\n",
      "3. 's-Gravenhage (Den Haag): 568.419 inwoners\n",
      "4. Utrecht: 376.435 inwoners\n",
      "5. Eindhoven: 249.054 inwoners\n",
      "6. Groningen: 244.807 inwoners\n",
      "7. Tilburg: 230.359 inwoners\n",
      "\n",
      "Specifiek voor Groningen: de gemeente Groningen zal in 2025 naar verwachting 244.807 inwoners hebben.\n",
      "\n",
      "De prognose laat zien dat Amsterdam veruit de grootste gemeente blijft, met bijna 1 miljoen inwoners, terwijl Tilburg de top 7 completeert met ruim 230.000 inwoners.\n"
     ]
    }
   ],
   "source": [
    "result = tool_agent.run(\n",
    "    \"Geef een overzicht van de top-7 gemeenten in Nederland met het grootste aantal inwoners in 2025. Laat ook het aantal inwoners van Groningen zien.\"\n",
    ")\n",
    "\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:31:38.301 Calling __main__.ToolAgent.run\n",
      "12:31:41.909   Agent response generated\n",
      "ðŸ”§ Claude gebruikt tool: get_inwoners_gemeente met input: {'gemeente_naam': 'Eindhoven', 'jaar': '2023'}\n",
      "12:31:47.643   Agent response generated\n",
      "Ik heb de gegevens gevonden. Eindhoven heeft momenteel 243.730 inwoners (peildatum 2023). \n",
      "\n",
      "Als elk van deze inwoners 15 euro zou betalen, dan zou de totale som zijn:\n",
      "243.730 Ã— 15 = 3.655.950 euro\n",
      "\n",
      "Dus als alle inwoners van Eindhoven in 2025 15 euro betalen, zou je 3.655.950 euro krijgen.\n",
      "\n",
      "Belangrijke opmerking: Dit is een hypothetische berekening. In de praktijk zou zoiets uiteraard niet zomaar kunnen plaatsvinden zonder nadere context of wettelijke grondslag.\n"
     ]
    }
   ],
   "source": [
    "result = tool_agent.run(\n",
    "    \"Als alle inwoners uit Eindhoven in 2025 15 euro betalen, hoeveel krijg ik dan.\",\n",
    ")\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voeg geheugen toe aan de agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemAgent(ToolAgent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.memory = []\n",
    "\n",
    "    def add_memory(self, role, memory):\n",
    "        self.memory.append({\"role\": role, \"content\": memory})\n",
    "\n",
    "    def get_memory(self):\n",
    "        return self.memory\n",
    "\n",
    "    @logfire.instrument()\n",
    "    def run(self, user_input):\n",
    "        self.memory.append({\"role\": \"user\", \"content\": user_input})\n",
    "        input = \"\"\n",
    "        for message in self.memory:\n",
    "            input += f\"role': {message['role']}, 'content': {message['content']}\\n\"\n",
    "\n",
    "        response = super().run(input)\n",
    "        self.memory.append({\"role\": \"assistant\", \"content\": response.content[0].text})\n",
    "        return response\n",
    "\n",
    "\n",
    "mem_agent = MemAgent(\n",
    "    name=\"mem_agent\",\n",
    "    system_prompt=\"je bent een agent die op alle vragen een verstandig antwoord geeft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:30:21.843 Calling __main__.MemAgent.run\n",
      "12:30:21.844   Calling __main__.ToolAgent.run\n",
      "12:30:26.044     Agent response generated\n",
      "ðŸ”§ Claude gebruikt tool: calculate_btw met input: {'bedrag': 100}\n",
      "12:30:28.488     Agent response generated\n",
      "Stap 2: Bereken de korting op het bedrag inclusief BTW\n"
     ]
    }
   ],
   "source": [
    "result = mem_agent.run(\n",
    "    \"ik koop een product X voor 100 euro exclusief BTW, bereken de BTW. Ik krijg van de leverancier ook nog 15% korting op het bedrag inclusief BTW. Geef een overzicht wat ik moet betalen en hoe dat is samengesteld\"\n",
    ")\n",
    "\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mem_agent.run(\n",
    "    \"wat was ook alweer het btw bedrag van het eerder gekochte product X en hoeveel korting kreeg ik. Zoek dit uit de conversatie hiervoor.\"\n",
    ")\n",
    "\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gebruik een MCP server om de tools te gebruiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp import ClientSession\n",
    "from mcp.client.sse import sse_client\n",
    "from contextlib import ExitStack\n",
    "import requests\n",
    "import asyncio\n",
    "\n",
    "\n",
    "class MCPAgent(LLMAgent):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialiseer de Anthropic MCP client\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Initialize session and client objects\n",
    "\n",
    "    @logfire.instrument()\n",
    "    async def run(self, user_input):\n",
    "\n",
    "        # connect to the server via SSE\n",
    "        async with sse_client(\"http://localhost:8050/sse\") as (\n",
    "            read_stream,\n",
    "            write_stream,\n",
    "        ):\n",
    "            async with ClientSession(read_stream, write_stream) as session:\n",
    "                # initialize the session\n",
    "                await session.initialize()\n",
    "                print(\"Available tools:\")\n",
    "                tools_result = await session.list_tools()\n",
    "                for tool in tools_result.tools:\n",
    "                    print(f\"  - {tool.name}: {tool.description}\")\n",
    "\n",
    "                # convert to the anthropic format\n",
    "                anthropic_tools = []\n",
    "                for tool in tools_result.tools:\n",
    "                    anthropic_tool = {\n",
    "                        \"name\": tool.name,\n",
    "                        \"description\": tool.description,\n",
    "                        \"input_schema\": tool.inputSchema,\n",
    "                    }\n",
    "                    anthropic_tools.append(anthropic_tool)\n",
    "\n",
    "                # set the tools\n",
    "                self.tools = anthropic_tools\n",
    "\n",
    "                # run the agent\n",
    "                response = self.client.messages.create(\n",
    "                    model=self.model,\n",
    "                    max_tokens=3000,\n",
    "                    system=self.system_prompt,\n",
    "                    tools=self.tools,\n",
    "                    messages=[{\"role\": \"user\", \"content\": user_input}],\n",
    "                )\n",
    "\n",
    "                # Check if Claude wants to use tools\n",
    "                if response.stop_reason == \"tool_use\":\n",
    "                    tool_results = []\n",
    "\n",
    "                    for content in response.content:\n",
    "                        if content.type == \"tool_use\":\n",
    "                            tool_name = content.name\n",
    "                            tool_input = content.input\n",
    "                            tool_id = content.id\n",
    "\n",
    "                            print(\n",
    "                                f\"ðŸ”§ Claude gebruikt tool: {tool_name} met input: {tool_input}\"\n",
    "                            )\n",
    "\n",
    "                            # Execute the tool\n",
    "                            tool_result = await session.call_tool(\n",
    "                                tool_name, {**tool_input}\n",
    "                            )\n",
    "\n",
    "                            tool_results.append(\n",
    "                                {\n",
    "                                    \"type\": \"tool_result\",\n",
    "                                    \"tool_use_id\": tool_id,\n",
    "                                    \"content\": tool_result.content[0].text,\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "                # Get final response with tool results\n",
    "                final_response = self.client.messages.create(\n",
    "                    model=self.model,\n",
    "                    max_tokens=1000,\n",
    "                    tools=self.tools,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": user_input},\n",
    "                        {\"role\": \"assistant\", \"content\": response.content},\n",
    "                        {\"role\": \"user\", \"content\": tool_results},\n",
    "                    ],\n",
    "                )\n",
    "                # Log the final response to Logfire\n",
    "                logfire.info(\n",
    "                    \"Agent response generated\",\n",
    "                    agent_name=self.name,\n",
    "                    user_input=user_input,\n",
    "                    response=final_response,\n",
    "                )\n",
    "\n",
    "        # Extract the response text\n",
    "        if final_response:\n",
    "            response = final_response\n",
    "        else:\n",
    "            response = response\n",
    "\n",
    "        response_text = (\n",
    "            response.content[0].text if hasattr(response, \"content\") else response\n",
    "        )\n",
    "        # Log the response to Logfire\n",
    "        logfire.info(\n",
    "            \"Agent response generated\",\n",
    "            agent_name=self.name,\n",
    "            user_input=user_input,\n",
    "            response=response_text,\n",
    "            model=self.model,\n",
    "            response_length=len(response_text),\n",
    "        )\n",
    "        return response\n",
    "\n",
    "\n",
    "mcp_agent = MCPAgent(\n",
    "    name=\"mcp_agent\",\n",
    "    system_prompt=\"je bent een agent die op alle vragen een verstandig antwoord geeft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await mcp_agent.run(\"wat is de btw van 100 euro\")\n",
    "\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await mcp_agent.run(\"Hoeveel inwoners heeft Rotterdam?\")\n",
    "\n",
    "print(result.content[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
